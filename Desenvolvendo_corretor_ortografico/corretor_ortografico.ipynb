{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desenvolvendo um corretor ortográfico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste projeto utilizei algumas técnicas de **NLP** e lógica de programação em python para desenvolver um modelo capaz de corrigir aluns erros de digitação, como caracteres faltantes ou a mais, caracteres digitados errados ou invertidos.\n",
    "\n",
    "Ao final do projeto foram desenvolvidos 2 corretores, um com taxa de acerto de 55% e o outro com acerto de 76%, algo que ainda pode ser melhorado inserindo mais exemplos de palavras para aumentar o vocabulário do corretor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Importando a biblioteca utilizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "aGKjtTlayi5M"
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Abrindo e exibindo os primeiros registros do arquivo usado como vocabulário para o corretor de palavras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LVLKh3WgCQ0I",
    "outputId": "1393d654-8d66-4211-b260-67395fe70ada"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "imagem \n",
      "\n",
      "Temos a seguinte classe que representa um usuário no nosso sistema:\n",
      "\n",
      "java\n",
      "\n",
      "Para salvar u\n"
     ]
    }
   ],
   "source": [
    "with open('artigos.txt','r', encoding=\"utf8\") as f:\n",
    "  artigos = f.read()\n",
    "\n",
    "print(artigos[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tokenizando o texto**\n",
    "\n",
    "- A função abaixo serve para retornar apenas as  palavras de um texto, onde foi feito a tokenização e padronização para que retorne todas as palavras separadas e com escrita em letras minúsculas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qYmnxKNz1GET",
    "outputId": "50e89267-74d0-4845-d5ad-a346d3f9b395"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Biena\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "xCMy_tYn-Rvc"
   },
   "outputs": [],
   "source": [
    "#  função que recebe um texto retorna apenas uma lista com palavras\n",
    "def tokenizacao(texto):\n",
    "  lista_de_palavras=[]\n",
    "  lista_tokens = nltk.tokenize.word_tokenize(texto)\n",
    "  lista_de_tokens = [palavra.lower() for palavra in lista_tokens]\n",
    "  for token in lista_de_tokens:\n",
    "    if token.isalpha():\n",
    "      lista_de_palavras.append(token)\n",
    "\n",
    "  return lista_de_palavras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Exempplo da função de tokenização e normalização funcionando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LlF2LvZUDXLi",
    "outputId": "86718e35-4bd5-43f2-9e31-2728672a3996"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['olá',\n",
       " 'seja',\n",
       " 'bem',\n",
       " 'vindo',\n",
       " 'ao',\n",
       " 'projeto',\n",
       " 'corretor',\n",
       " 'ortográfico',\n",
       " 'utilizando',\n",
       " 'técnicas',\n",
       " 'de',\n",
       " 'nlp']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste='OLÁ, SEJA BEM VINDO ao projeto corretor ortográfico utilizando Técnicas DE  NlP'\n",
    "\n",
    "tokenizacao(teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2kvC7C3Dt7H"
   },
   "source": [
    "- Verificando q quantidade de palavras no arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GY8IKm2jCa4m",
    "outputId": "31307d07-518d-43f6-fe44-0efa40c854db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403106\n"
     ]
    }
   ],
   "source": [
    "# quantidade de palavras no arquivo artigos.txt\n",
    " \n",
    "print(len(tokenizacao(artigos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GiZX__FnEm3x",
    "outputId": "cee73050-1f17-47c1-8ac7-49b4cc06d4c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18465\n"
     ]
    }
   ],
   "source": [
    "#  removendo palavras repetidas\n",
    "print(len(set(tokenizacao(artigos))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desenvolvendo a função corretor ortográfico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  A função corretor  será desenvolvida por meio de outras funções, sendo elas:\n",
    "\n",
    "**Inserir letras**: onde simula casos em que esquecemos se alguma letra na digitação das palavras\n",
    "\n",
    "**Remover letras**: onde simula casos em que digitamos letras a mais. \n",
    "\n",
    "**Trocar letras** onde simula casos de escrita de alguma letra errada errada, e a função irá subistituir letra por letra da palavra por outras letras e formando novas palavras.\n",
    "\n",
    "**Inverte letras** onde simula casos de escrita de alguma letra na posição errada, e a função irá inverter a posição das letras na palavra formando novas palavras.\n",
    "\n",
    "**Gerador de palavras** esta função abrange as 4 funções acima e gera um conjunto de palavras possíveis a partir da palavra digitada e que deve ser corrigida.\n",
    "\n",
    "\n",
    "A performance do corretor será avaliada calculando a probabilidade das palavras geradas, dividindo pela quatidade total de palavras que tem no arquivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "YBHr71uhK3JJ"
   },
   "outputs": [],
   "source": [
    "#  criando função para fatiar e criar novas palavras\n",
    "def inserir_letras(fatias):\n",
    "  novas_palavras=[]\n",
    "  letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "  for E,D in fatias:\n",
    "    for letra in letras:\n",
    "      novas_palavras.append(E+ letra + D)\n",
    "\n",
    "  return novas_palavras\n",
    "\n",
    "def deletando_caracteres(fatias):\n",
    "    novas_palavras = []\n",
    "    for E, D in fatias:\n",
    "        novas_palavras.append(E + D[1:])\n",
    "    return novas_palavras\n",
    "\n",
    "def troca_letra(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzáàãâéèêíìóòõôúùûç'\n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D[1:])\n",
    "    return novas_palavras\n",
    "\n",
    "def inverte_letra(fatias):\n",
    "    novas_palavras = []\n",
    "    for E, D in fatias:\n",
    "        if len(D)>1:\n",
    "            novas_palavras.append(E + D[1] + D[0] + D[2:])\n",
    "    return novas_palavras\n",
    "\n",
    "def gerador_de_palavras(palavra):\n",
    "  fatias=[]\n",
    "  for i in range(len(palavra)+1):\n",
    "    fatias.append((palavra[:i], palavra[i:]))\n",
    "\n",
    "  palavras_geradas=inserir_letras(fatias)\n",
    "  palavras_geradas+=deletando_caracteres(fatias)\n",
    "  palavras_geradas+=troca_letra(fatias)\n",
    "  palavras_geradas+=inverte_letra(fatias)\n",
    "  \n",
    "  return palavras_geradas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta etapa foram criadas as funções:\n",
    "\n",
    "**Probabilidade** que utiliza a frequência de cada palavra  dividido pela quantidade total de palavrass do arquivo.\n",
    "\n",
    "**Corretor** que utilizada a função probalbilidade para em meio as palavras eradas selecionar a que tem maior probabilidade e inidicar como sendo a palavra correta.\n",
    "\n",
    "**Cria dados teste** que cria uma lista de dados de teste para avaliar o corretor.\n",
    "\n",
    "**Avaliador** que avalia a performance do correto de palavras, dando a taxa de acerto e a % de palavras que não estão no vocabulário do corretor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('de', 15502),\n",
       " ('o', 14056),\n",
       " ('que', 12230),\n",
       " ('a', 11099),\n",
       " ('e', 10501),\n",
       " ('para', 7710),\n",
       " ('um', 6368),\n",
       " ('é', 5899),\n",
       " ('uma', 5220),\n",
       " ('do', 5124)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lista com todas as palavras separadas e normalizadas do arquivo \"artigos.txt\"\n",
    "lista_normalizada =  tokenizacao(artigos)\n",
    "\n",
    "# calculando a frequencia de cada palavra usando o método FreqDist e xibindo as 10 palavras mais comuns\n",
    "frequencia = nltk.FreqDist(lista_normalizada)\n",
    "\n",
    "frequencia.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_palavras=len(lista_normalizada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3ziwUanGNQ-m"
   },
   "outputs": [],
   "source": [
    "# criando a função probalibilidade para saber a probabilidade de cada palavra\n",
    "def probabilidade(palavra_gerada):\n",
    "    probabilidade=frequencia[palavra_gerada]/total_palavras\n",
    "    return probabilidade\n",
    "\n",
    "# criando a função corretor de palavras\n",
    "def corretor(palavra):\n",
    "    palavras_geradas = gerador_de_palavras(palavra)\n",
    "    palavra_correta = max(palavras_geradas, key=probabilidade)\n",
    "    return palavra_correta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando dados de teste para avaliar o corretor\n",
    "def cria_dados_teste(nome_arquivo):\n",
    "    lista_palavras_teste = []\n",
    "    f = open(nome_arquivo, \"r\",encoding='utf-8')\n",
    "    for linha in f:\n",
    "        correta, errada = linha.split()\n",
    "        lista_palavras_teste.append((correta, errada))\n",
    "    f.close()\n",
    "    return lista_palavras_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('podemos', 'pyodemos'),\n",
       " ('esse', 'esje'),\n",
       " ('já', 'jrá'),\n",
       " ('nosso', 'nossov'),\n",
       " ('são', 'sãêo'),\n",
       " ('dos', 'dosa'),\n",
       " ('muito', 'muifo'),\n",
       " ('imagem', 'iômagem'),\n",
       " ('sua', 'ósua'),\n",
       " ('também', 'tambéùm')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_teste = cria_dados_teste(\"palavras.txt\")\n",
    "lista_teste[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa de acerto é 76.34 % de 186 palavras\n",
      "A porcentagem de palavras desconhecidas é de 6.99%\n"
     ]
    }
   ],
   "source": [
    "def avaliador(testes, vocabulario):\n",
    "    numero_palavras = len(testes)\n",
    "    acerto = 0\n",
    "    desconhecida = 0\n",
    "    for correta, errada in testes:\n",
    "        desconhecida += (correta not in vocabulario)\n",
    "        palavra_corrigida = corretor(errada)\n",
    "        if palavra_corrigida == correta:\n",
    "            acerto += 1\n",
    "    \n",
    "    taxa_acerto = round(acerto*100/numero_palavras, 2)\n",
    "    taxa_desconhecida = round(desconhecida*100/numero_palavras, 2)\n",
    "    print(f'''Taxa de acerto é {taxa_acerto} % de {numero_palavras} palavras\\n'''\n",
    "          f'''A porcentagem de palavras desconhecidas é de {taxa_desconhecida}%''')\n",
    "\n",
    "\n",
    "vocabulario = set(lista_normalizada)\n",
    "avaliador(lista_teste, vocabulario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementando o corretor de palavras com  2 correções\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  criando um novo gerador de palavras\n",
    "def gerador_turbinado(palavras_geradas):\n",
    "    novas_palavras = []\n",
    "    for palavra in palavras_geradas:\n",
    "        novas_palavras += gerador_de_palavras(palavra)\n",
    "    return novas_palavras\n",
    "\n",
    "palavra = \"lóiigica\"\n",
    "palavras_g = gerador_turbinado(gerador_de_palavras(palavra))\n",
    "\"lógica\" in palavras_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando um novo corretor usando o corretor já desenvolvido\n",
    "def novo_corretor(palavra):\n",
    "    palavras_geradas = gerador_de_palavras(palavra)\n",
    "    palavras_turbinado = gerador_turbinado(palavras_geradas)\n",
    "    todas_palavras = set(palavras_geradas + palavras_turbinado)\n",
    "    candidatos = [palavra]\n",
    "    for palavra in todas_palavras:\n",
    "        if palavra in vocabulario:\n",
    "            candidatos.append(palavra)\n",
    "    palavra_correta = max(candidatos, key=probabilidade)\n",
    "    return palavra_correta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa de acerto é 55.38 % de 186 palavras\n",
      "A porcentagem de palavras desconhecidas é de 6.99%\n"
     ]
    }
   ],
   "source": [
    "def avaliador(testes, vocabulario):\n",
    "    numero_palavras = len(testes)\n",
    "    acerto = 0\n",
    "    desconhecida = 0\n",
    "    for correta, errada in testes:\n",
    "        desconhecida += (correta not in vocabulario)\n",
    "        palavra_corrigida = novo_corretor(errada)\n",
    "        if palavra_corrigida == correta:\n",
    "            acerto += 1\n",
    "    \n",
    "    taxa_acerto = round(acerto*100/numero_palavras, 2)\n",
    "    taxa_desconhecida = round(desconhecida*100/numero_palavras, 2)\n",
    "    print(f'''Taxa de acerto é {taxa_acerto} % de {numero_palavras} palavras\\n'''\n",
    "          f'''A porcentagem de palavras desconhecidas é de {taxa_desconhecida}%''')\n",
    "\n",
    "\n",
    "vocabulario = set(lista_normalizada)\n",
    "avaliador(lista_teste, vocabulario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coreção da palavra lgica do 1º corretor: \"lógica\" \n",
      "Correção da palavra lgica do 2º corretor: \"fica\"\"\n"
     ]
    }
   ],
   "source": [
    "# palavra correta=\"lógica\"\n",
    "palavra='lgica'\n",
    "print(f'Coreção da palavra {palavra} do 1º corretor: \"{corretor(palavra)}\" ')\n",
    "print(f'Correção da palavra {palavra} do 2º corretor: \"{novo_corretor(palavra)}\"\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coreção da palavra lóiigica do 1º corretor: \"alóiigica\" \n",
      "Correção da palavra lóiigica do 2º corretor: \"lógica\"\"\n"
     ]
    }
   ],
   "source": [
    "# palavra correta=\"lógica\"\n",
    "palavra='lóiigica'\n",
    "print(f'Coreção da palavra {palavra} do 1º corretor: \"{corretor(palavra)}\" ')\n",
    "print(f'Correção da palavra {palavra} do 2º corretor: \"{novo_corretor(palavra)}\"\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "corretor_ortografico.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
